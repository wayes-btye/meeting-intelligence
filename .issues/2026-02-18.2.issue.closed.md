# [\#2 Issue](https://github.com/wayes-btye/meeting-intelligence/issues/2) `closed`: Ingestion pipeline: transcript parsing, chunking, embedding
**Labels**: `pipeline`


#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) opened issue at [2026-02-18 12:00](https://github.com/wayes-btye/meeting-intelligence/issues/2):

## Description
Parse .vtt/.txt/.json transcripts, implement naive and speaker-turn chunking strategies, embed with OpenAI text-embedding-3-small, store in Supabase pgvector. Accept audio upload via AssemblyAI transcription with speaker diarization.

## Tasks
- [ ] Transcript parsers for .vtt, .txt, .json formats
- [ ] Naive chunking (fixed-size with overlap)
- [ ] Speaker-turn chunking (split on speaker boundaries)
- [ ] OpenAI text-embedding-3-small integration
- [ ] Store chunks + embeddings in Supabase pgvector
- [ ] AssemblyAI transcription with speaker diarization
- [ ] Meeting metadata extraction and storage

## Acceptance Criteria
- Upload a transcript, see chunks in Supabase with embeddings
- Both chunking strategies produce valid chunks with metadata
- Audio files are transcribed with speaker labels

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) commented at [2026-02-18 16:56](https://github.com/wayes-btye/meeting-intelligence/issues/2#issuecomment-3921956770):

## Progress: Ingestion pipeline in progress

Branch: `feat/2-ingestion`

Building:
- Transcript parsers (VTT, plain text, JSON/AssemblyAI/MeetingBank)
- Chunking strategies (naive fixed-size, speaker-turn)
- OpenAI embedding integration
- Supabase storage layer
- End-to-end pipeline function
- Tests for parsers and chunking

Will lint and test before pushing.

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) commented at [2026-02-18 16:59](https://github.com/wayes-btye/meeting-intelligence/issues/2#issuecomment-3921983308):

## Completed

PR: #12

- 6 source files in src/ingestion/ (models, parsers, chunking, embeddings, storage, pipeline)
- 22 tests passing (parsers + chunking, no API keys needed)
- Test fixture: sample.vtt with council meeting data
- Lint + format clean

Ready for merge.

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) commented at [2026-02-18 22:23](https://github.com/wayes-btye/meeting-intelligence/issues/2#issuecomment-3923526226):

**Post-merge audit finding:**

AssemblyAI audio transcription was not implemented. Only text transcript parsing (VTT, TXT, JSON) was built. Specifically:

- The acceptance criteria included "Audio files transcribed via AssemblyAI" — this was not done.
- The `assemblyai` package is listed in `pyproject.toml` but is never imported or used anywhere in `src/`.
- The `ASSEMBLYAI_API_KEY` config field exists but is never consumed by any code.
- The UI file uploader (`src/ui/app.py`) accepts `mp3`, `wav`, and `m4a` files and displays a message about AssemblyAI transcription, but the ingest endpoint (`src/api/routes/ingest.py`) calls `raw.decode("utf-8")` on all uploads — this will crash with `UnicodeDecodeError` on binary audio files.
- There is no transcription module (no `src/ingestion/transcriber.py` or similar).

Audio transcription was not implemented — only text parsing was built. The UI should either stop accepting audio files or the transcription pipeline needs to be implemented.

This needs to be addressed in a follow-up issue.


-------------------------------------------------------------------------------



[Export of Github issue for [wayes-btye/meeting-intelligence](https://github.com/wayes-btye/meeting-intelligence). Generated on 2026.02.20 at 04:16:27.]
