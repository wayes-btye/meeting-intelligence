# [\#33 Issue](https://github.com/wayes-btye/meeting-intelligence/issues/33) `closed`: test: improve test coverage — real fixtures, integration tests, pipeline e2e

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) opened issue at [2026-02-20 00:28](https://github.com/wayes-btye/meeting-intelligence/issues/33):

## Problem

Current test suite has 108 tests but they are all unit-level with mocked data and toy fixtures. They do not test:
- The database layer (no live Supabase connection)
- The embedding pipeline (no live OpenAI calls)
- The retrieval pipeline (no actual vector search)
- The generation step (no live Claude calls)
- Any end-to-end flow

The single test fixture is `tests/fixtures/sample.vtt` — a handful of speaker turns. This does not represent real meeting data.

## What to Build

**1. Real fixtures**
- Add 2-3 MeetingBank transcripts to `tests/fixtures/meetingbank/`
- These are real city council meetings with known structure, speaker labels, and reference summaries
- Enables assertions like "answer should mention topic X" rather than just "answer is non-empty"

**2. Integration tests (marked `@pytest.mark.expensive`)**
- `test_pipeline_integration.py` — full ingestion: load transcript → chunk → embed → store in Supabase → verify chunk count and metadata
- `test_retrieval_integration.py` — live vector search: query against known ingested data, verify top-k results contain expected content
- These require live API keys (OPENAI_API_KEY, SUPABASE_URL, SUPABASE_KEY)

**3. End-to-end test (marked `@pytest.mark.expensive`)**
- Upload transcript → ingest → query "What were the main topics?" → verify answer is coherent and attributed
- This is the golden path test — if this passes, the core system works

**4. Evaluation runner test**
- After Issue #23 is fixed: `test_evaluation.py` includes an expensive test that runs the full eval pipeline on a small test set (5 questions) and verifies metrics are produced

## Acceptance Criteria

- `pytest -m "not expensive"` still fast and passing (unit tests unchanged)
- `pytest -m "expensive"` runs full pipeline and passes when API keys are present
- At least one MeetingBank transcript in `tests/fixtures/`
- End-to-end golden path test exists and passes

## Notes

This is infrastructure work, not feature work. But for an AI Engineering Lead role, demonstrating a proper test pyramid is important.

Related PRD items: F67, F68, F69




-------------------------------------------------------------------------------



[Export of Github issue for [wayes-btye/meeting-intelligence](https://github.com/wayes-btye/meeting-intelligence). Generated on 2026.02.28 at 03:55:48.]
