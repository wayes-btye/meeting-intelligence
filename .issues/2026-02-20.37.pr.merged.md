# [\#37 PR](https://github.com/wayes-btye/meeting-intelligence/pull/37) `merged`: fix: evaluation runner entry point + test coverage improvements (#23, #33)

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) opened issue at [2026-02-20 07:29](https://github.com/wayes-btye/meeting-intelligence/pull/37):

## Summary

- **Issue #23**: `python -m src.evaluation.runner` previously crashed with no `__main__` block. Added argparse CLI with `--meetings`, `--output`, `--strategies`, `--test-set`, `--no-cross-check`. The `--help` flag now exits 0.
- **Issue #33**: Only fixture was `tests/fixtures/sample.vtt`. Added a real MeetingBank format fixture and updated the JSON parser to handle the canonical `transcription` key format.
- **README fix**: Replaced incorrect "RAGAS + DeepEval metrics" claim with accurate "Claude-as-judge evaluation" description.

## Changes

| File | What changed |
|------|-------------|
| `src/evaluation/runner.py` | Added `__main__` block with argparse CLI; added `_build_arg_parser`, `_parse_strategy`, `_load_transcripts_from_supabase` helpers |
| `src/ingestion/parsers.py` | `parse_json` now handles 3 formats: AssemblyAI `utterances`, MeetingBank canonical `transcription` (new), internal `segments` |
| `tests/fixtures/meetingbank/sample_council_meeting.json` | New 26-segment city council meeting in canonical MeetingBank format (`meeting_id`, `transcription[]`, `summary`) |
| `tests/test_evaluation.py` | Added `test_runner_callable_as_module` — asserts `--help` exits 0 |
| `tests/test_ingestion.py` | Added `TestMeetingBankRealFixture` — 2 tests: parser correctness + naive chunking against real fixture |
| `tests/test_pipeline_integration.py` | New file — 3 `@pytest.mark.expensive` golden-path integration tests |
| `README.md` | Fixed RAGAS/DeepEval claim -> Claude-as-judge description |

## Test results

```
pytest tests/ -m "not expensive"   ->  111 passed, 3 deselected
ruff check src/                    ->  All checks passed
```

## Manual verification needed

The integration tests in `tests/test_pipeline_integration.py` cannot run in CI (live API keys required):

```bash
# 1. Start the API server (port 8030 for WT3)
PORT=8030 make api

# 2. In a second terminal, run the expensive tests
pytest -m expensive tests/test_pipeline_integration.py -v

# 3. Verify python -m src.evaluation.runner --help works
python -m src.evaluation.runner --help
```

Tests exercise: ingest -> Supabase storage -> query -> answer validation -> cleanup.

## Band-aid fix assessment

| Fix | Type | Notes |
|-----|------|-------|
| `__main__` block | Proper fix | Wires existing `run_evaluation()` without touching eval logic |
| `parse_json` transcription format | Proper fix | Missing format case; added with clear docstring |
| Synthetic fixture | Minor limitation | `data/meetingbank/` not present in worktree; fixture is representative of real format but not an actual download |
| Integration tests | Proper | Complete and correct; marked expensive for CI exclusion |

Closes #23, Closes #33

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) commented at [2026-02-20 10:59](https://github.com/wayes-btye/meeting-intelligence/pull/37#issuecomment-3933087045):

@claude review this

#### <img src="https://avatars.githubusercontent.com/in/1236702?v=4" width="50">[claude](https://github.com/apps/claude) commented at [2026-02-20 10:59](https://github.com/wayes-btye/meeting-intelligence/pull/37#issuecomment-3933088149):

**Claude finished @wayes-btye's task in 1m 52s** —— [View job](https://github.com/wayes-btye/meeting-intelligence/actions/runs/22221462344)

---
### Code Review — PR #37

- [x] Gather context
- [x] Read changed files
- [x] Cross-reference API routes, models, storage
- [x] Post review findings

---

Overall the PR is solid and well-structured. The `__main__` block (Issue #23) is a clean fix, the `parse_json` MeetingBank format addition is correct, and the test organisation is good. However, the Codex-flagged P1/P2 bugs are real and will cause runtime failures. Details below.

---

### Confirmed bugs (from Codex review)

#### P1 — Wrong column names in `_load_transcripts_from_supabase()` [`runner.py:347–357`]

```python
# Current (broken)
client.table("meetings")
    .select("meeting_id, transcript_text")
    .eq("meeting_id", mid)
    ...
transcripts[mid] = result.data["transcript_text"]
```

`src/ingestion/storage.py:store_meeting()` inserts records with no `meeting_id` column — the primary key is the Postgres-generated `id` (UUID), and the transcript column is `raw_transcript`. The correct query is:

```python
client.table("meetings")
    .select("id, raw_transcript")
    .eq("id", mid)
    ...
transcripts[mid] = result.data["raw_transcript"]
```

As-is, `python -m src.evaluation.runner --meetings <any-id>` will fail at the Supabase query level even when valid data exists.

[Fix this →](https://claude.ai/code?q=In%20src%2Fevaluation%2Frunner.py%20fix%20_load_transcripts_from_supabase%20function%3A%20change%20the%20select%20from%20%22meeting_id%2C%20transcript_text%22%20to%20%22id%2C%20raw_transcript%22%2C%20change%20the%20.eq%20filter%20from%20%22meeting_id%22%20to%20%22id%22%2C%20and%20change%20result.data%5B%22transcript_text%22%5D%20to%20result.data%5B%22raw_transcript%22%5D.%20Branch%3A%20fix%2F23-33-eval-tests&repo=wayes-btye/meeting-intelligence)

#### P2 — Integration tests target non-existent routes with wrong schemas [`test_pipeline_integration.py:89–113`]

**Path mismatch:** The API registers routes under `/api/` prefix (`POST /api/ingest`, `POST /api/query`) — see `src/api/routes/ingest.py:20` and `src/api/routes/query.py:20`. The tests call `/ingest` and `/query` directly (no prefix).

**Schema mismatch for ingest:** `POST /api/ingest` is `multipart/form-data` (`UploadFile` + `Form` fields). The test posts JSON. These are incompatible content types — the endpoint returns 422.

**Schema mismatch for query:** `QueryRequest` (`src/api/models.py:10–15`) has `meeting_id: str | None` and `strategy: RetrievalStrategy`. The test sends `meeting_ids` (a list) and `retrieval_strategy` (wrong key name) — both fields will be silently ignored, and the query runs over all meetings without the intended meeting filter.

```python
# Current (broken)
ingest_resp = client.post(f"{API_BASE_URL}/ingest", json=ingest_payload)
#                                                   ^^^^ JSON, but endpoint expects multipart

query_payload = {
    "meeting_ids": [TEST_MEETING_ID],   # key doesn't exist in QueryRequest
    "retrieval_strategy": "hybrid",      # key doesn't exist in QueryRequest (should be "strategy")
}
```

[Fix this →](https://claude.ai/code?q=In%20tests%2Ftest_pipeline_integration.py%20fix%20all%20three%20issues%3A%201%29%20Change%20%22%2Fingest%22%20to%20%22%2Fapi%2Fingest%22%20and%20%22%2Fquery%22%20to%20%22%2Fapi%2Fquery%22%20everywhere.%202%29%20Change%20the%20ingest%20call%20from%20json%20body%20to%20multipart%20form-data%20matching%20the%20UploadFile%2BForm%20signature%20in%20src%2Fapi%2Froutes%2Fingest.py%20-%20use%20httpx%20files%20and%20data%20params.%203%29%20Change%20query%20payload%20keys%20from%20meeting_ids%2FretriEval_strategy%20to%20meeting_id%2Fstrategy%20matching%20QueryRequest%20in%20src%2Fapi%2Fmodels.py.%20Note%20the%20ingest%20endpoint%20takes%20%22title%22%20not%20%22meeting_id%22%20-%20the%20meeting%20ID%20is%20generated%20server-side.%20Branch%3A%20fix%2F23-33-eval-tests&repo=wayes-btye/meeting-intelligence)

---

### Minor issues

#### 1. `TestJSONParser.test_meetingbank_format` tests the wrong format [`test_ingestion.py:109`]

The test is named `test_meetingbank_format` but it actually exercises the **internal `segments` format**, not the new MeetingBank `transcription` format. There is no unit test in `TestJSONParser` for the new branch added in `parsers.py:138–147`. The `TestMeetingBankRealFixture` class covers this via the fixture file, but a dedicated unit test for the `transcription` key path (like the existing AssemblyAI and segments tests) is missing.

#### 2. Hardcoded port in integration tests [`test_pipeline_integration.py:41`]

```python
API_BASE_URL = "http://localhost:8030"
```

Port 8030 is the worktree 3 allocation per `CLAUDE.md`. Anyone running from the main workspace (port 8000) or another worktree will get connection refused. Should be:

```python
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")
```

#### 3. `httpx` not verified in requirements

`httpx` is imported inside the expensive test functions. Since these are excluded from CI it won't break the test run, but the dev experience is poor if `httpx` isn't in `requirements.txt`. Worth checking and adding if absent.

---

### What's good

- The `__main__` block is cleanly separated from `run_evaluation()` — no changes to eval logic.
- `_parse_strategy()` with `split(":", 1)` and explicit validation is the right approach.
- The `_generate_or_load_test_set()` helper with `os.makedirs(..., exist_ok=True)` corner case (`or "."`) is handled correctly.
- `parse_json` format dispatch is clean — adding the `transcription` branch fits the existing pattern.
- `TestMeetingBankRealFixture` tests are well-scoped and assert the right things (speaker labels, non-negative timestamps, non-empty text).
- `test_runner_callable_as_module` using `subprocess.run` is the right way to test the `__main__` entry point.

---

**Summary:** The P1 column-name bug will silently break `--meetings` mode at runtime; the P2 endpoint/schema mismatches mean the integration tests exercise a completely different code path than intended. Both should be fixed before merge. The minor issues are non-blocking but worth addressing.


-------------------------------------------------------------------------------



[Export of Github issue for [wayes-btye/meeting-intelligence](https://github.com/wayes-btye/meeting-intelligence). Generated on 2026.03.01 at 04:23:01.]
