# [\#50 PR](https://github.com/wayes-btye/meeting-intelligence/pull/50) `merged`: chore: Cloud Run + Vercel auto-deploy (#31)

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) opened issue at [2026-02-21 07:06](https://github.com/wayes-btye/meeting-intelligence/pull/50):

## Summary

- **Dockerfile**: CMD now uses `${PORT:-8000}` â€” Cloud Run injects `$PORT` at runtime (was hardcoded to 8000, would fail Cloud Run health checks)
- **vercel.json**: Added at repo root with `rootDirectory: frontend` so Vercel auto-detects the Next.js app in the subdirectory
- **.github/workflows/deploy.yml**: On push to `main` â€” builds Docker image, pushes to Artifact Registry, deploys to Cloud Run service `meeting-intelligence-api`

## Test plan

- [x] `docker build` clean (exit 0, tested locally)
- [x] `GET /health` responds `{"status":"healthy"}` on default port 8000
- [x] `GET /health` responds on port 8080 with `PORT=8080` env var (Cloud Run simulation)
- [ ] CI lint + test pass on this PR
- [ ] After merge: first Cloud Run deploy triggered by push to main
- [ ] After Cloud Run URL known: set `NEXT_PUBLIC_API_URL` in Vercel dashboard + redeploy

## Setup required before deploy works

See full instructions in [Issue #31 comment](https://github.com/wayes-btye/meeting-intelligence/issues/31#issuecomment-3938316537) â€” GitHub secrets (GCP + API keys) and GCP one-time setup.

Closes #31

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

#### <img src="https://avatars.githubusercontent.com/u/151667361?v=4" width="50">[wayes-btye](https://github.com/wayes-btye) commented at [2026-02-21 07:23](https://github.com/wayes-btye/meeting-intelligence/pull/50#issuecomment-3938357139):

@claude review this please

#### <img src="https://avatars.githubusercontent.com/in/1236702?v=4" width="50">[claude](https://github.com/apps/claude) commented at [2026-02-21 07:23](https://github.com/wayes-btye/meeting-intelligence/pull/50#issuecomment-3938357440):

**Claude finished @wayes-btye's task in 1m 35s** â€”â€” [View job](https://github.com/wayes-btye/meeting-intelligence/actions/runs/22252722488)

---
### PR Review: Cloud Run + Vercel Auto-Deploy

- [x] Gathering context
- [x] Reading changed files
- [x] Analyzing workflow, Dockerfile, and vercel.json
- [x] Posting review feedback

---

Overall the approach is sound â€” Workload Identity Federation (keyless), SHA-tagged images, and minimal `vercel.json` are all good choices. One real bug needs fixing before this will work reliably on Cloud Run; the rest are suggestions.

---

### ðŸ”´ Critical: Dockerfile CMD â€” PID 1 / signal problem

**File:** `Dockerfile:12`

```dockerfile
# Current (broken for graceful shutdown)
CMD uvicorn src.api.main:app --host 0.0.0.0 --port ${PORT:-8000}
```

Shell-form `CMD` runs as `/bin/sh -c "uvicorn ..."`, making the shell PID 1. Cloud Run sends `SIGTERM` to PID 1 on scale-down/redeploy â€” the shell receives it and exits immediately, killing uvicorn without draining in-flight requests. This is what Codex flagged.

Fix: prepend `exec` so the shell replaces itself with uvicorn:

```dockerfile
CMD exec uvicorn src.api.main:app --host 0.0.0.0 --port ${PORT:-8000}
```

`exec` promotes uvicorn to PID 1, so signals reach it directly and graceful shutdown works. This is the standard pattern for shell-form CMD when you need variable expansion. [Fix this â†’](https://claude.ai/code?q=In%20the%20Dockerfile%20on%20branch%20feat%2F31-cloud-run%2C%20line%2012%3A%20change%20%22CMD%20uvicorn%22%20to%20%22CMD%20exec%20uvicorn%22%20to%20fix%20the%20PID%201%20signal%20forwarding%20issue%20for%20Cloud%20Run%20graceful%20shutdown&repo=wayes-btye/meeting-intelligence)

---

### ðŸŸ¡ Important: API keys in `--set-env-vars` (secret exposure risk)

**File:** `.github/workflows/deploy.yml:47`

```yaml
--set-env-vars "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }},OPENAI_API_KEY=..."
```

Two issues:
1. **Log exposure:** GitHub Actions redacts `${{ secrets.* }}` in log output, but the expanded values are embedded in a single string argument â€” if any downstream GCP audit log captures the `gcloud` invocation arguments, all keys are visible in plaintext.
2. **Comma in values:** If any secret value contains a comma, `--set-env-vars` will silently misparse it.

The correct Cloud Run approach is [Secret Manager + `--set-secrets`](https://cloud.google.com/run/docs/configuring/services/secrets). For a demo/assessment project this may be an acceptable trade-off â€” just worth knowing. Alternatively, pass each var as a separate `--update-env-vars` flag.

---

### ðŸŸ¡ Missing `--port` flag in Cloud Run deploy

**File:** `.github/workflows/deploy.yml:43`

Cloud Run injects `$PORT=8080` and the Dockerfile now respects it â€” so the container will listen on 8080. But Cloud Run also needs to know what port to send traffic to. Without `--port`, it defaults to 8080, which happens to match. This works today but is implicit. Adding `--port 8080` makes the intent explicit and avoids surprises if the default ever changes.

```yaml
gcloud run deploy $SERVICE \
  --image $IMAGE:$GITHUB_SHA \
  --port 8080 \   # add this
  ...
```

---

### ðŸŸ¡ `GOOGLE_API_KEY` secret â€” undocumented dependency

**File:** `.github/workflows/deploy.yml:47`

`GOOGLE_API_KEY` is injected into Cloud Run but isn't listed in `CLAUDE.md`'s required keys. If this secret isn't set in GitHub, the deploy step will pass but the env var will be an empty string in Cloud Run, which could cause silent failures for any Gemini/Google AI calls. Worth either documenting it in `CLAUDE.md` or removing it if unused.

---

### ðŸŸ¢ Minor suggestions

**`vercel.json`:** `"framework": "nextjs"` is redundant â€” Vercel auto-detects Next.js from `package.json`. Not harmful, just noise.

**CI caching:** The `docker build` step has no layer cache. Each run pulls and rebuilds from scratch. For faster deploys, consider:
```yaml
- name: Build and push Docker image
  run: |
    docker buildx build \
      --cache-from $IMAGE:latest \
      --cache-to type=inline \
      -t $IMAGE:$GITHUB_SHA -t $IMAGE:latest \
      --push .
```

**No `--memory` / `--min-instances`:** Default is 512MB RAM and 0 min instances (cold starts). Fine for a demo; worth revisiting if the embedding or transcription workloads OOM.

---

### What's good

- Workload Identity Federation (keyless auth) is the right call â€” no long-lived SA key JSON in secrets
- SHA-tagged images + `latest` tag is a solid pattern (rollback via SHA, convenience via latest)
- `vercel.json` at repo root is the correct minimal config for a monorepo subdirectory
- `id-token: write` permission is correctly scoped to only the deploy job
- CORS in `src/api/main.py` (`allow_origin_regex` for `*.vercel.app`) is already correct

**Summary:** The `exec` fix in the Dockerfile is the only blocker â€” everything else will work without it, but you'll get non-graceful container terminations under normal Cloud Run operations. The rest are hardening suggestions.


-------------------------------------------------------------------------------



[Export of Github issue for [wayes-btye/meeting-intelligence](https://github.com/wayes-btye/meeting-intelligence). Generated on 2026.02.25 at 04:21:35.]
